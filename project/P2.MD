1. The inner k loop cannot be parallelized without incurring data dependency errors. I achieve the best performance when the rowsA i loop is parallelized, this makes sense as we see the best performace when the i loop is the first loop. For this algorithm this code improves as we scale from 1 to 4 threads, speeding up the process from 25 to 15 seconds. However it breaks down when we attempt 8 threads, with a time of 33 seconds.

2. for a 2048 x 2048 run on a local machine, as we reduce the tile size from the matrix to smaller dimensions, we see a drastic improvement in time until we use a tile size of 64. At this point there are small improvements, before the time begins increasing again. As we increase the threads from 1 to 8 threads, we see a great inprovement in the compute time, from 13 seconds unparallelized to 2.4 seconds at 8 threads. For my local machine, the best parameters are a tile size of 8 at 8 threads.

3.
runMode set to blas
number of threads set to 1
number of threads=1
Time blas 2747246

4. I am unable to set up the interactive shell in Perlmutter so I am interpretting usmans data here.

## Cache misses summary

| Criteria                 | Loop           | Tiled         | Blas         |
| ------------------------ |  -----------   | ------------- | ------------ |
| L1-dcache-load-misses:u  | 17,391,437,485 | 9,543,251,267 | 1,203,277,069|
| dTLB-load-misses:u       | 18,847         | 17,433        | 334,824      |
| l2_pf_hit_l2:u           | 15,916,972,095 | 3,388,007,186 | 1,331,616,998|
| l2_pf_miss_l2_hit_l3:u   | 1,706,488,857  | 9,612,889,715 | 326,356,463  |

When observing the performance analytics in comparison of the three methods, we see that the loop implementation has the highest frequency of L1 misses, and L2 hits. Because we see the loop method missing a lot of data in L1 cache and eventually finding the data in L2, we can deduce that these searches will cumulatively accrue extra compute time. It's also worth noting that this implementation is execute more searches for data to accomplish the same operation.

The tiled method has less searches  than loop method, which aligns with the expectation that the tiling accomplishes the same operation while execute fewer numbers of searches for relevant data. We do note that tiled has the highest rate of misses to L2 to hits to L3, but its still a huge improvement on looped

BLAS demonstates the fewest number of L1 missses, L2 hits, and L2 misses. It is most efficient in executing relevant searches and keeping relevant data in the L1 cache.